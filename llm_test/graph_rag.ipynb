{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "from langchain_community.document_loaders import PDFPlumberLoader\n",
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "\n",
    "import os\n",
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "def read_files(dir):\n",
    "    return [f for f in os.listdir(dir) if os.path.isfile(os.path.join(dir, f))]\n",
    "\n",
    "def sort_by_ext(file_dir: str,\n",
    "                file_name: str):\n",
    "    file_list = []\n",
    "    file_list.append(file_name)\n",
    "    ext_dict = defaultdict(list)\n",
    "    for file in file_list:\n",
    "        ext = file.split('.')[-1]\n",
    "        file_path = os.path.join(file_dir, file)\n",
    "        ext_dict[ext].append(file_path)\n",
    "    return dict(ext_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pdf(self, file_path):\n",
    "    loader = PDFPlumberLoader(file_path)\n",
    "    loaded_pdf = loader.load()\n",
    "    for chunked in loaded_pdf:\n",
    "        chunked.page_content = chunked.page_content.replace(\"\\x00\", \"\")\n",
    "        for i in self.add_filter:\n",
    "            chunked.page_content = re.sub(i, \"#\"*len(i), chunked.page_content)\n",
    "        for k, v in self.def_metadata.items():\n",
    "            chunked.metadata[str(k)] = v\n",
    "        for k, v in self.add_metadata.items():\n",
    "            chunked.metadata[str(k)] = v\n",
    "    return loaded_pdf\n",
    "\n",
    "def load_csv(self, file_path):\n",
    "    loader = CSVLoader(file_path)\n",
    "    loaded_csv = loader.load()\n",
    "    for chunked in loaded_csv:\n",
    "        chunked.page_content = chunked.page_content.replace(\"\\x00\", \"\")\n",
    "        for i in self.add_filter:\n",
    "            chunked.page_content = re.sub(i, \"#\"*len(i), chunked.page_content)\n",
    "        for k, v in self.def_metadata.items():\n",
    "            chunked.metadata[str(k)] = v\n",
    "        for k, v in self.add_metadata.items():\n",
    "            chunked.metadata[str(k)] = v\n",
    "    return loaded_csv\n",
    "\n",
    "def load_txt(self, file_path):\n",
    "    loader = open(file_path)\n",
    "    text = loader.read()\n",
    "    for i in self.add_filter:\n",
    "        text = re.sub(i, \"#\"*len(i), text)\n",
    "    text = re.sub(\"\\x00\", \"\", text)\n",
    "    metadata = {'source': file_path}\n",
    "    for k, v in self.def_metadata.items():\n",
    "        metadata[str(k)] = v\n",
    "    for k, v in self.add_metadata.items():\n",
    "        metadata[str(k)] = v\n",
    "    loaded_txt = [Document(page_content=text, metadata=metadata)]\n",
    "    return loaded_txt\n",
    "\n",
    "def load_json(self, file_path):\n",
    "    import pickle\n",
    "\n",
    "    with open(file_path,\"rb\") as fr:\n",
    "        loaded_json_rdb = pickle.load(fr)\n",
    "    text = loaded_json_rdb['content']\n",
    "\n",
    "    for i in self.add_filter:\n",
    "        text = re.sub(i, \"#\"*len(i), text)\n",
    "    text = re.sub(\"\\x00\", \"\", text)\n",
    "    metadata = {'source': file_path}\n",
    "    for k, v in self.def_metadata.items():\n",
    "        metadata[str(k)] = v\n",
    "    for k, v in self.add_metadata.items():\n",
    "        metadata[str(k)] = v\n",
    "    loaded_txt = [Document(page_content=text, metadata=metadata)]\n",
    "    return loaded_txt\n",
    "\n",
    "def load(self):\n",
    "    result = {}\n",
    "    files_by_ext = sort_by_ext(file_dir=self.file_dir, file_name=self.file_name)\n",
    "    for k, v in files_by_ext.items():\n",
    "        if k == 'pdf':\n",
    "            for file_path in v:\n",
    "                result[str(file_path.split('/')[-1])] = self.load_pdf(file_path)\n",
    "        elif k == 'csv':\n",
    "            for file_path in v:\n",
    "                result[str(file_path.split('/')[-1])] = self.load_csv(file_path)\n",
    "        elif k == 'txt':\n",
    "            for file_path in v:\n",
    "                result[str(file_path.split('/')[-1])] = self.load_txt(file_path)\n",
    "        elif k == 'json':\n",
    "            for file_path in v:\n",
    "                result[str(file_path.split('/')[-1])] = self.load_json(file_path)\n",
    "    return [result]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
