# ğŸ“„ app.py
import streamlit as st
from dotenv import load_dotenv
import pandas as pd
from typing import Annotated, TypedDict
from langgraph.graph import StateGraph, END
from langchain_core.runnables import RunnableLambda
from langchain_core.messages import HumanMessage
from langchain_openai import ChatOpenAI
import re
import io

# Load API key
load_dotenv()

# âœ… ìƒíƒœ ì •ì˜
class GraphState(TypedDict):
    question: Annotated[str, "question"]
    context: Annotated[str, "context"]
    answer: Annotated[str, "answer"]

# âœ… GPT ëª¨ë¸ ì„¤ì •
llm = ChatOpenAI(model="gpt-3.5-turbo", temperature=0)

# âœ… ë…¸ë“œ 1: ì§ˆë¬¸ ê³ ì •
def handle_question(state: GraphState) -> GraphState:
    state["question"] = (
        "í…Œì´ë¸” ì»¬ëŸ¼ì˜ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì¹´í…Œê³ ë¦¬í˜• ì»¬ëŸ¼ì´ ë¬´ì—‡ì¸ì§€ ì•Œë ¤ì¤˜. "
        "ë‹µë³€ì€ ì»¬ëŸ¼ëª…ë§Œ ë‚˜ì—´í•´ì¤˜."
    )
    return state

# âœ… ë…¸ë“œ 2: GPT API í˜¸ì¶œ
def generate_answer(state: GraphState) -> GraphState:
    st.info("ğŸ’¬ GPTê°€ ë‹µë³€ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤...")
    messages = [
        HumanMessage(content=f"ì§ˆë¬¸: {state['question']}\në¬¸ë§¥: {state['context']}")
    ]
    response = llm.invoke(messages)
    state["answer"] = response.content
    return state

# âœ… LangGraph ì›Œí¬í”Œë¡œìš° êµ¬ì„±
workflow = StateGraph(GraphState)
workflow.add_node("handle_question", RunnableLambda(handle_question))
workflow.add_node("generate_answer", RunnableLambda(generate_answer))
workflow.set_entry_point("handle_question")
workflow.add_edge("handle_question", "generate_answer")
workflow.add_edge("generate_answer", END)
app = workflow.compile()

# âœ… Streamlit UI
st.title("ğŸ“Š í…Œì´ë¸” ë¶„ì„ ë„ìš°ë¯¸")
st.write("CSV íŒŒì¼ì„ ì—…ë¡œë“œí•˜ë©´ ì»¬ëŸ¼ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì¹´í…Œê³ ë¦¬í˜• ì»¬ëŸ¼ì„ íƒì§€í•˜ê³  ì„ íƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

# 1. CSV ì—…ë¡œë“œ
uploaded_file = st.file_uploader("ğŸ“‚ CSV íŒŒì¼ ì—…ë¡œë“œ", type=["csv"])

if uploaded_file is not None:
    df = pd.read_csv(uploaded_file)
    st.write("ğŸ” ì—…ë¡œë“œëœ ë°ì´í„° (ë¯¸ë¦¬ë³´ê¸°)")
    st.dataframe(df.head())

    # 1. LLMì—ê²Œ ì¹´í…Œê³ ë¦¬í˜• ì»¬ëŸ¼ ì¶”ì • ìš”ì²­ (ì°¸ê³ ìš©)
    if 'category_analysis_done' not in st.session_state:
        st.session_state['category_analysis_done'] = False
    if 'category_analysis_result' not in st.session_state:
        st.session_state['category_analysis_result'] = None

    show_analysis_ui = False
    if not st.session_state['category_analysis_done']:
        if st.button("GPTì—ê²Œ ì¹´í…Œê³ ë¦¬í˜• ì»¬ëŸ¼ ë¶„ì„ ìš”ì²­"):
            column_info = f"í…Œì´ë¸”ëª…: ì—…ë¡œë“œëœ í…Œì´ë¸”\nì»¬ëŸ¼ëª…: {list(df.columns)}"
            input_state = {
                "question": "í…Œì´ë¸” ì»¬ëŸ¼ì˜ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì¹´í…Œê³ ë¦¬í˜• ì»¬ëŸ¼ì´ ë¬´ì—‡ì¸ì§€ ì•Œë ¤ì¤˜. ë‹µë³€ì€ ë°˜ë“œì‹œ ['ì»¬ëŸ¼1', 'ì»¬ëŸ¼2', ...] í˜•íƒœì˜ íŒŒì´ì¬ ë¦¬ìŠ¤íŠ¸ë¡œë§Œ í•´ì¤˜. ë‹¤ë¥¸ ì„¤ëª…ì€ í•˜ì§€ë§ˆ.",
                "context": column_info,
                "answer": ""
            }
            result = app.invoke(input_state)
            st.session_state['category_analysis_result'] = result['answer']
            st.session_state['category_analysis_done'] = True
            show_analysis_ui = True
    else:
        show_analysis_ui = True

    if show_analysis_ui:
        st.success("âœ… GPTê°€ ì¶”ì •í•œ ì¹´í…Œê³ ë¦¬í˜• ì»¬ëŸ¼ì…ë‹ˆë‹¤:")
        if st.session_state['category_analysis_result']:
            st.markdown(f"**ğŸ§  GPT ë‹µë³€:**\n{st.session_state['category_analysis_result']}")
        st.info("ì¹´í…Œê³ ë¦¬í˜• ì»¬ëŸ¼ ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ì•„ë˜ì—ì„œ ì»¬ëŸ¼ì„ ì„ íƒí•˜ê³  ì¶”ê°€ ë¶„ì„ì„ ì§„í–‰í•˜ì„¸ìš”.")

        selected_columns = st.multiselect(
            "ğŸ“Œ ì‚¬ìš©í•  ì»¬ëŸ¼ì„ ì„ íƒí•˜ì„¸ìš”:",
            options=df.columns,
            default=[]
        )

        if selected_columns:
            st.subheader("ğŸ¯ ì„ íƒëœ ì»¬ëŸ¼ ë°ì´í„° (ë¯¸ë¦¬ë³´ê¸°)")
            st.dataframe(df[selected_columns].head())

            # 1. ì „ì²´ ì •ì œ ë° ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
            if st.button("ì„ íƒí•œ ì»¬ëŸ¼ ì „ì²´ ì •ì œ ë° ë‹¤ìš´ë¡œë“œ", key="refine_all"):
                refined_df = df.copy()
                all_mappings = {}
                mapping_errors = {}
                for col in selected_columns:
                    distinct_values = df[col].dropna().unique().tolist()
                    prompt = (
                        f"ë‹¤ìŒì€ '{col}' ì»¬ëŸ¼ì˜ DISTINCT ê°’ ë¦¬ìŠ¤íŠ¸ì•¼: {distinct_values}\n"
                        f"ë™ì¼í•œ ì˜ë¯¸ì¸ë° í‘œê¸°ê°€ ë‹¤ë¥¸ ê°’ì´ ìˆë‹¤ë©´ í•˜ë‚˜ë¡œ í†µì¼í•˜ê³ , ê° ì›ë˜ ê°’ì´ ì–´ë–¤ ê°’ìœ¼ë¡œ ë°”ë€Œì–´ì•¼ í•˜ëŠ”ì§€ ë°˜ë“œì‹œ íŒŒì´ì¬ ë”•ì…”ë„ˆë¦¬ í˜•íƒœë¡œë§Œ ë‹µí•´ì¤˜. ì˜ˆì‹œ: {{'ë‚¨': 'ë‚¨ì„±', 'ë‚¨ì': 'ë‚¨ì„±', 'M': 'ë‚¨ì„±', ...}}. ë‹¤ë¥¸ ì„¤ëª…ì€ í•˜ì§€ë§ˆ."
                    )
                    messages = [HumanMessage(content=prompt)]
                    response = llm.invoke(messages)
                    try:
                        mapping = eval(response.content)
                        if isinstance(mapping, dict):
                            all_mappings[col] = mapping
                            refined_df[col] = df[col].map(lambda x: mapping.get(str(x).strip(), x))
                        else:
                            mapping_errors[col] = "ë‹µë³€ì´ ë”•ì…”ë„ˆë¦¬ í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤. ì§ì ‘ í™•ì¸ í•„ìš”."
                    except Exception as e:
                        mapping_errors[col] = f"ë§¤í•‘ íŒŒì‹± ì‹¤íŒ¨: {e}. ë‹µë³€: {response.content}"

                # 2. ì»¬ëŸ¼ë³„ ë§¤í•‘ ê²°ê³¼ ì‹œê°í™”
                st.markdown("---")
                st.subheader("ğŸ§  ì»¬ëŸ¼ë³„ ì •ì œ ë§¤í•‘ ê²°ê³¼")
                for col in selected_columns:
                    with st.expander(f"[{col}] ë§¤í•‘ ê²°ê³¼ ë³´ê¸°"):
                        if col in all_mappings:
                            st.write("ì ìš©ëœ ë§¤í•‘:", all_mappings[col])
                        if col in mapping_errors:
                            st.warning(mapping_errors[col])

                # 3. ì •ì œëœ ì „ì²´ DataFrame(ì›ë³¸+ì •ì œì»¬ëŸ¼) ë‹¤ìš´ë¡œë“œ
                csv = refined_df.to_csv(index=False).encode('utf-8-sig')
                st.download_button(
                    label=f"ì •ì œëœ ì „ì²´ ë°ì´í„°(ì›ë³¸+ì •ì œì»¬ëŸ¼) CSV ë‹¤ìš´ë¡œë“œ",
                    data=csv,
                    file_name=f"refined_full_data.csv",
                    mime='text/csv',
                    key="download_all"
                )
        else:
            st.warning("âš ï¸ ìµœì†Œ í•˜ë‚˜ ì´ìƒì˜ ì»¬ëŸ¼ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")
else:
    st.info("CSV íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")