import streamlit as st
from dotenv import load_dotenv
import pandas as pd
from typing import Annotated, TypedDict
from langgraph.graph import StateGraph, END
from langchain_core.runnables import RunnableLambda
from langchain_core.messages import HumanMessage
from langchain_openai import ChatOpenAI
import re
import io

st.set_page_config(page_title="AI ë°ì´í„° í’ˆì§ˆ ë„êµ¬", layout="wide")
st.title("ğŸ“Š AI ê¸°ë°˜ ë°ì´í„° í’ˆì§ˆ ê´€ë¦¬ í”Œë«í¼")

uploaded_file = st.file_uploader("ğŸ“‚ CSV íŒŒì¼ ì—…ë¡œë“œ", type=["csv"])

if uploaded_file:
    df = pd.read_csv(uploaded_file)
    st.dataframe(df.head())

    # ğŸ“˜ í…Œì´ë¸” ì„¤ëª… ì…ë ¥
    table_description = st.text_area(
        "ğŸ“ ì´ í…Œì´ë¸”ì˜ ë°ì´í„°ì— ëŒ€í•œ ì„¤ëª…ì„ ì…ë ¥í•´ì£¼ì„¸ìš”:",
        placeholder="ì˜ˆ: ì´ í…Œì´ë¸”ì€ ê³ ê°ì˜ ê°œì¸ì •ë³´ì™€ êµ¬ë§¤ì´ë ¥ì„ í¬í•¨í•˜ê³  ìˆìŠµë‹ˆë‹¤.")

    # ğŸ” ê¸°ëŠ¥ë³„ ê´€ë ¨ ì»¬ëŸ¼ ë¶„ì„ ìš”ì²­ (í•­ì‹œ ë²„íŠ¼ ë…¸ì¶œ)
    if 'function_column_analysis' not in st.session_state:
        st.session_state['function_column_analysis'] = {}

    if st.button("ğŸ§  ê° ê¸°ëŠ¥ë³„ ê´€ë ¨ ì»¬ëŸ¼ê³¼ ì´ìœ  ë¶„ì„ ìš”ì²­"):
        if not table_description.strip():
            st.warning("âš ï¸ í…Œì´ë¸” ì„¤ëª…ì„ ë¨¼ì € ì…ë ¥í•´ì£¼ì„¸ìš”.")
        else:
            st.session_state['function_column_analysis'] = {}
            analysis_tasks = [
                "1) ë¹„ì •ìƒ ë°ì´í„° íƒì§€ ê¸°ëŠ¥",
                "2) ë°ì´í„° ê²°ì¸¡ê°’ ìë™ ë³´ì • ê¸°ëŠ¥",
                "3) êµ¬ì¡°(Meta) ê²°ì¸¡ê°’ ìë™ ë³´ì • ê¸°ëŠ¥",
                "4) ë„ë©”ì¸/ì½”ë“œ í‘œì¤€ ìë™ ìˆ˜ì • ê¸°ëŠ¥"
            ]
            for task in analysis_tasks:
                prompt = f"""
                            í…Œì´ë¸” ì„¤ëª…: {table_description}
                            ì»¬ëŸ¼ ëª©ë¡: {list(df.columns)}
                            ê¸°ëŠ¥: {task}
                            í•´ë‹¹ ê¸°ëŠ¥ê³¼ ê´€ë ¨ì„±ì´ ë†’ì€ ì»¬ëŸ¼ ë¦¬ìŠ¤íŠ¸ì™€ ê°„ë‹¨í•œ ì´ìœ ë¥¼ ì•Œë ¤ì¤˜. ë„ˆë¬´ ìì„¸í•˜ì§€ ì•Šê²Œ ê°„ê²°íˆ ì„¤ëª…í•´ì¤˜.
                         """
                response = llm.invoke([HumanMessage(content=prompt)])
                st.session_state['function_column_analysis'][task] = response.content

    if st.session_state.get('function_column_analysis'):
        for task, content in st.session_state['function_column_analysis'].items():
            if f'rendered_{task}' not in st.session_state:
                st.markdown(f"#### ğŸ” {task} ê´€ë ¨ ì»¬ëŸ¼ ë¶„ì„ ê²°ê³¼")
                full_text = ""
                placeholder = st.empty()
                for char in content:
                    full_text += char
                    placeholder.markdown(full_text + "â–Œ")
                    import time
                    time.sleep(0.005)
                placeholder.markdown(full_text)
                st.session_state[f'rendered_{task}'] = True
            else:
                st.markdown(f"#### ğŸ” {task} ê´€ë ¨ ì»¬ëŸ¼ ë¶„ì„ ê²°ê³¼")
                st.markdown(st.session_state['function_column_analysis'][task])