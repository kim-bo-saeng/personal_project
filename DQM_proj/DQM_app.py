# ğŸ“„ app.py
import streamlit as st
from dotenv import load_dotenv
import pandas as pd
from typing import Annotated, TypedDict
from langgraph.graph import StateGraph, END
from langchain_core.runnables import RunnableLambda
from langchain_core.messages import HumanMessage
from langchain_openai import ChatOpenAI
import re
import io

# âœ… í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="AI ë°ì´í„° í’ˆì§ˆ ë„êµ¬", layout="wide")
st.title("ğŸ“Š AI ê¸°ë°˜ ë°ì´í„° í’ˆì§ˆ ê´€ë¦¬ í”Œë«í¼")

# âœ… API í‚¤ ë¡œë”©
load_dotenv()

# âœ… ìƒíƒœ ì •ì˜
class GraphState(TypedDict):
    question: Annotated[str, "question"]
    context: Annotated[str, "context"]
    answer: Annotated[str, "answer"]

# âœ… AI ëª¨ë¸ ì„¤ì •
llm = ChatOpenAI(model="gpt-3.5-turbo", temperature=0)

# âœ… LangGraph ì •ì˜
workflow = StateGraph(GraphState)
def handle_question(state: GraphState) -> GraphState:
    return state

def generate_answer(state: GraphState) -> GraphState:
    st.info("ğŸ’¬ AIê°€ ë‹µë³€ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤...")
    messages = [
        HumanMessage(content=f"ì§ˆë¬¸: {state['question']}\në¬¸ë§¥: {state['context']}")
    ]
    response = llm.invoke(messages)
    state["answer"] = response.content
    return state

workflow.add_node("handle_question", RunnableLambda(handle_question))
workflow.add_node("generate_answer", RunnableLambda(generate_answer))
workflow.set_entry_point("handle_question")
workflow.add_edge("handle_question", "generate_answer")
workflow.add_edge("generate_answer", END)
app = workflow.compile()

# âœ… Streamlit UI
uploaded_file = st.file_uploader("ğŸ“‚ CSV íŒŒì¼ ì—…ë¡œë“œ", type=["csv"])

if uploaded_file:
    df = pd.read_csv(uploaded_file)
    st.dataframe(df.head())

    # ğŸ“˜ í…Œì´ë¸” ì„¤ëª… ì…ë ¥
    table_description = st.text_area(
        "ğŸ“ ì´ í…Œì´ë¸”ì˜ ë°ì´í„°ì— ëŒ€í•œ ì„¤ëª…ì„ ì…ë ¥í•´ì£¼ì„¸ìš”:",
        placeholder="ì˜ˆ: ì´ í…Œì´ë¸”ì€ ê³ ê°ì˜ ê°œì¸ì •ë³´ì™€ êµ¬ë§¤ì´ë ¥ì„ í¬í•¨í•˜ê³  ìˆìŠµë‹ˆë‹¤."
    )

    # ğŸ” ê¸°ëŠ¥ë³„ ê´€ë ¨ ì»¬ëŸ¼ ë¶„ì„ ìš”ì²­ (í•­ì‹œ ë²„íŠ¼ ë…¸ì¶œ)
    if 'function_column_analysis' not in st.session_state:
        st.session_state['function_column_analysis'] = {}

    if st.button("ğŸ§  ê° ê¸°ëŠ¥ë³„ ê´€ë ¨ ì»¬ëŸ¼ê³¼ ì´ìœ  ë¶„ì„ ìš”ì²­"):
        if not table_description.strip():
            st.warning("âš ï¸ í…Œì´ë¸” ì„¤ëª…ì„ ë¨¼ì € ì…ë ¥í•´ì£¼ì„¸ìš”.")
        else:
            st.session_state['function_column_analysis'] = {}
            analysis_tasks = [
                "1) ë¹„ì •ìƒ ë°ì´í„° íƒì§€ ê¸°ëŠ¥",
                "2) ë°ì´í„° ê²°ì¸¡ê°’ ìë™ ë³´ì • ê¸°ëŠ¥",
                "3) êµ¬ì¡°(Meta) ê²°ì¸¡ê°’ ìë™ ë³´ì • ê¸°ëŠ¥",
                "4) ë„ë©”ì¸/ì½”ë“œ í‘œì¤€ ìë™ ìˆ˜ì • ê¸°ëŠ¥"
            ]
            for task in analysis_tasks:
                prompt = f"""
í…Œì´ë¸” ì„¤ëª…: {table_description}
ì»¬ëŸ¼ ëª©ë¡: {list(df.columns)}
ê¸°ëŠ¥: {task}
í•´ë‹¹ ê¸°ëŠ¥ê³¼ ê´€ë ¨ì„±ì´ ë†’ì€ ì»¬ëŸ¼ ë¦¬ìŠ¤íŠ¸ì™€ ê°„ë‹¨í•œ ì´ìœ ë¥¼ ì•Œë ¤ì¤˜. ë„ˆë¬´ ìì„¸í•˜ì§€ ì•Šê²Œ ê°„ê²°íˆ ì„¤ëª…í•´ì¤˜.
"""
                response = llm.invoke([HumanMessage(content=prompt)])
                st.session_state['function_column_analysis'][task] = response.content

    if st.session_state.get('function_column_analysis'):
        for task, content in st.session_state['function_column_analysis'].items():
            if f'rendered_{task}' not in st.session_state:
                st.markdown(f"#### ğŸ” {task} ê´€ë ¨ ì»¬ëŸ¼ ë¶„ì„ ê²°ê³¼")
                full_text = ""
                placeholder = st.empty()
                for char in content:
                    full_text += char
                    placeholder.markdown(full_text + "â–Œ")
                    import time
                    time.sleep(0.005)
                placeholder.markdown(full_text)
                st.session_state[f'rendered_{task}'] = True
            else:
                st.markdown(f"#### ğŸ” {task} ê´€ë ¨ ì»¬ëŸ¼ ë¶„ì„ ê²°ê³¼")
                st.markdown(st.session_state['function_column_analysis'][task])

    # ğŸ” ë¶„ì„ ê¸°ëŠ¥ ì„ íƒ
    with st.container():
        st.markdown("### ğŸ” ë¶„ì„ ê¸°ëŠ¥ ì„ íƒ")
        selected_analysis = st.selectbox("ìˆ˜í–‰í•  ë¶„ì„ ê¸°ëŠ¥ì„ ì„ íƒí•˜ì„¸ìš”:", [
            "1) ë¹„ì •ìƒ ë°ì´í„° íƒì§€ ê¸°ëŠ¥",
            "2) ë°ì´í„° ê²°ì¸¡ê°’ ìë™ ë³´ì • ê¸°ëŠ¥",
            "3) êµ¬ì¡°(Meta) ê²°ì¸¡ê°’ ìë™ ë³´ì • ê¸°ëŠ¥",
            "4) ë„ë©”ì¸/ì½”ë“œ í‘œì¤€ ìë™ ìˆ˜ì • ê¸°ëŠ¥ (êµ¬í˜„ ê¸°ëŠ¥)"
        ], key="analysis_selectbox")

    selected_columns = st.multiselect("ğŸ“Œ ë¶„ì„í•  ì»¬ëŸ¼ì„ ì„ íƒí•˜ì„¸ìš”:", options=df.columns)

    if selected_columns:
        if selected_analysis == "1) ë¹„ì •ìƒ ë°ì´í„° íƒì§€ ê¸°ëŠ¥":
            st.subheader("ğŸš§ [ì˜ˆì •] ë¹„ì •ìƒ ë°ì´í„° íƒì§€ ê¸°ëŠ¥")
            st.info("í–¥í›„ êµ¬í˜„ ì˜ˆì •: ì„ íƒëœ ì»¬ëŸ¼ì˜ ì´ìƒê°’, ë…¼ë¦¬ì  ì˜¤ë¥˜ ë“±ì„ íƒì§€í•©ë‹ˆë‹¤.")

        elif selected_analysis == "2) ë°ì´í„° ê²°ì¸¡ê°’ ìë™ ë³´ì • ê¸°ëŠ¥":
            st.subheader("ğŸš§ [ì˜ˆì •] ë°ì´í„° ê²°ì¸¡ê°’ ìë™ ë³´ì • ê¸°ëŠ¥")
            st.info("í–¥í›„ êµ¬í˜„ ì˜ˆì •: NULL/NaN ê°’ì„ AIê°€ ì ì ˆí•˜ê²Œ ì±„ì›Œì¤ë‹ˆë‹¤.")

        elif selected_analysis == "3) êµ¬ì¡°(Meta) ê²°ì¸¡ê°’ ìë™ ë³´ì • ê¸°ëŠ¥":
            st.subheader("ğŸš§ [ì˜ˆì •] ë©”íƒ€ë°ì´í„° ê²°ì¸¡ê°’ ë³´ì • ê¸°ëŠ¥")
            st.info("í–¥í›„ êµ¬í˜„ ì˜ˆì •: ë°ì´í„° íƒ€ì…, ìŠ¤í‚¤ë§ˆ ì •ë³´ ëˆ„ë½ ë¶€ë¶„ì„ ìë™ ë¶„ì„í•©ë‹ˆë‹¤.")

        elif selected_analysis == "4) ë„ë©”ì¸/ì½”ë“œ í‘œì¤€ ìë™ ìˆ˜ì • ê¸°ëŠ¥ (êµ¬í˜„ ê¸°ëŠ¥)":
            if st.button("ğŸ§  AI ë¶„ì„ ë° ì •ì œ ìˆ˜í–‰"):
                refined_df = df.copy()
                st.session_state['refined_df'] = refined_df
                st.session_state['mapping_results'] = {}

                for col in selected_columns:
                    distinct_values = df[col].dropna().unique().tolist()

                    issue_prompt = (
                        f"ë‹¤ìŒì€ '{col}' ì»¬ëŸ¼ì˜ DISTINCT ê°’ ë¦¬ìŠ¤íŠ¸ì•¼: {distinct_values}\n"
                        "ì´ ì»¬ëŸ¼ì— ë°ì´í„° í’ˆì§ˆ ë¬¸ì œê°€ ìˆì„ì§€ íŒë‹¨í•´ì¤˜. "
                        "ì˜ˆ: ê°’ì´ í†µì¼ë˜ì§€ ì•Šì•˜ê±°ë‚˜, ë¹„ì–´ ìˆëŠ” ê°’ì´ ìˆê±°ë‚˜, ì˜ëª»ëœ ê°’ì´ ìˆëŠ” ê²½ìš° ë“± ê°€ëŠ¥í•œ ë¬¸ì œë¥¼ ëª¨ë‘ ì„¤ëª…í•´ì¤˜."
                    )
                    issue_response = llm.invoke([HumanMessage(content=issue_prompt)])

                    refine_prompt = (
                        f"ë‹¤ìŒì€ '{col}' ì»¬ëŸ¼ì˜ DISTINCT ê°’ ë¦¬ìŠ¤íŠ¸ì•¼: {distinct_values}\n"
                        "ë™ì¼í•œ ì˜ë¯¸ì¸ë° í‘œê¸°ê°€ ë‹¤ë¥¸ ê°’ì´ ìˆë‹¤ë©´ í•˜ë‚˜ë¡œ í†µì¼í•˜ê³ , "
                        "ê° ì›ë˜ ê°’ì´ ì–´ë–¤ ê°’ìœ¼ë¡œ ë°”ë€Œì–´ì•¼ í•˜ëŠ”ì§€ ë°˜ë“œì‹œ íŒŒì´ì¬ ë”•ì…”ë„ˆë¦¬ í˜•íƒœë¡œë§Œ ë‹µí•´ì¤˜. "
                        "ì˜ˆ: {{'ë‚¨': 'ë‚¨ì„±', 'M': 'ë‚¨ì„±', 'ì—¬': 'ì—¬ì„±'}}"
                    )
                    refine_response = llm.invoke([HumanMessage(content=refine_prompt)])

                    try:
                        mapping = eval(refine_response.content)
                        if isinstance(mapping, dict):
                            refined_df[col] = df[col].map(lambda x: mapping.get(str(x).strip(), x))
                            st.session_state['mapping_results'][col] = {
                                "issue": issue_response.content,
                                "mapping": mapping,
                            }
                        else:
                            st.session_state['mapping_results'][col] = {
                                "issue": issue_response.content,
                                "error": "LLM ì‘ë‹µì´ ë”•ì…”ë„ˆë¦¬ í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤.",
                            }
                    except Exception as e:
                        st.session_state['mapping_results'][col] = {
                            "issue": issue_response.content,
                            "error": f"ë§¤í•‘ íŒŒì‹± ì‹¤íŒ¨: {e}\nì‘ë‹µ: {refine_response.content}",
                        }

            # ê²°ê³¼ ì¶œë ¥
            if 'mapping_results' in st.session_state:
                st.subheader("ğŸ“‹ ë¶„ì„ ë° ì •ì œ ê²°ê³¼")

                for col, result in st.session_state['mapping_results'].items():
                    with st.expander(f"ğŸ“Œ [{col}] ì»¬ëŸ¼ ë¶„ì„ ê²°ê³¼", expanded=False):
                        st.markdown("ğŸ” **ë¬¸ì œì  ë¶„ì„:**")
                        st.write(result.get("issue", "ì—†ìŒ"))

                        if "mapping" in result:
                            st.markdown("ğŸ”§ **ì ìš©ëœ ë§¤í•‘:**")
                            st.write(result["mapping"])
                            st.markdown("ğŸ“Š **ì •ì œëœ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°:**")
                            st.dataframe(st.session_state['refined_df'][[col]].head(10))
                        elif "error" in result:
                            st.error(result["error"])

                csv = st.session_state['refined_df'].to_csv(index=False).encode("utf-8-sig")
                st.download_button(
                    label="ğŸ’¾ ì •ì œëœ ì „ì²´ ë°ì´í„° CSV ë‹¤ìš´ë¡œë“œ",
                    data=csv,
                    file_name="refined_data.csv",
                    mime="text/csv",
                )
else:
    st.info("ğŸ“¥ CSV íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")