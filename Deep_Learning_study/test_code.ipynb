{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터를 불러와서 학습할 수 있는 형태로 변환해주는 단계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습에 활용할 최초의 데이터를 불러오는 작업\n",
    "with open('abalone.csv') as csvfile:\n",
    "    csvreader = csv.reader(csvfile)\n",
    "    next(csvreader, None)\n",
    "    rows = []\n",
    "    for row in csvreader:\n",
    "        rows.append(row)\n",
    "\n",
    "# 인풋과 아웃풋의 차원을 설정해 주고 data를 텐서화 시켜주는 작업\n",
    "input_cnt , output_cnt = 10,1\n",
    "data = np.zeros([len(rows),input_cnt+output_cnt])\n",
    "\n",
    "# 불러온 데이터를 0으로 채워진 텐서구조에 넣어주기\n",
    "for n, row in enumerate(rows):\n",
    "    if row[0] == \"I\" : data[n,0] = 1\n",
    "    if row[0] == \"M\" : data[n,1] = 1\n",
    "    if row[0] == \"F\" : data[n,2] = 1\n",
    "    data[n,3:] = row[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 학습 및 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: loss=33.602, accuracy=0.557/0.807\n",
      "Epoch 2: loss=8.136, accuracy=0.819/0.813\n",
      "Epoch 3: loss=7.475, accuracy=0.813/0.809\n",
      "Epoch 4: loss=7.359, accuracy=0.811/0.808\n",
      "Epoch 5: loss=7.271, accuracy=0.810/0.809\n",
      "Epoch 6: loss=7.201, accuracy=0.811/0.808\n",
      "Epoch 7: loss=7.140, accuracy=0.810/0.809\n",
      "Epoch 8: loss=7.086, accuracy=0.811/0.809\n",
      "Epoch 9: loss=7.036, accuracy=0.810/0.810\n",
      "Epoch 10: loss=6.997, accuracy=0.811/0.810\n",
      "\n",
      "Final Test : final accuracy = 0.810\n"
     ]
    }
   ],
   "source": [
    "# 초기 weight,bias를 설정해줌 : 정규분포를 갖는 난수값으로 초기 설정을 해줌)\n",
    "# 정규분포 난수값의 평균과 표준편차를 설정하여 가중치의 파라미터를 초기화 할때 사용한다\n",
    "RND_MEAN = 0\n",
    "RND_STD = 0.0030\n",
    "\n",
    "# 학습률을 설정(하이퍼파라미터)\n",
    "LEARNING_LATE = 0.001\n",
    "\n",
    "weight = np.random.normal(RND_MEAN,RND_STD,[input_cnt , output_cnt])\n",
    "bias = np.zeros([output_cnt])\n",
    "\n",
    "# 에포크 횟수(전체 학습횟수)와 미니배치 크기(한번에 학습하는 크기)를 설정하고 리포트 보고 주기를 설정\n",
    "epoch_count = 10\n",
    "mb_size = 10\n",
    "report = 1\n",
    "\n",
    "# 데이터를 섞고 랜덤으로 추출하여 학습하기 위한 데이터를 준비\n",
    "shuffle_map = np.arange(data.shape[0])                   # 데이터하나하나에 순번을 붙여주는 작업\n",
    "np.random.shuffle(shuffle_map)                           # 순번을 섞는 작업\n",
    "step_count = int(data.shape[0] * 0.8) // mb_size         # 데이터를 한번에 학습할 크기로 전체크기를 나눠 전체를 학습하기 위해 몇회를 해야되는지의 값\n",
    "test_begin_idx = step_count * mb_size                    # 테스트 데이터가 시작될 시작점의 번호(해당 인덱스를 기준으로 학습데이터와 테스트 데이터를 나누면됨)\n",
    "\n",
    "# 데이터를 학습및 테스트\n",
    "for epoch in range(epoch_count):\n",
    "    losses, accs = [], []\n",
    "\n",
    "    for n in range(step_count):\n",
    "        if n == 0:\n",
    "            np.random.shuffle(shuffle_map[:test_begin_idx])                   # 에포크가 한번 끝나고 다시 학습을 할때마다 데이터를 섞어준다, 데이터는 8:2로 나눠져있으며 인덱스값으로 구분\n",
    "        train_x = data[shuffle_map[mb_size*n:mb_size*(n+1)]][:, :-output_cnt] # 데이터에서 가장 마지막값을 제외한 나머지 값이 학습 데이터이다 => x\n",
    "        train_y = data[shuffle_map[mb_size*n:mb_size*(n+1)]][:, -output_cnt:] # 데이터에서 가장 마지막값은 정답인 정답데이터 이다 => y\n",
    "        \n",
    "        \n",
    "        # forward path 연산\n",
    "        output_train_x = np.matmul(train_x,weight) + bias\n",
    "        \n",
    "        diff = output_train_x - train_y\n",
    "        loss = np.mean(np.square(diff))\n",
    "\n",
    "        # step마다 loss와acc를 계산\n",
    "        accuracy = 1 - np.mean(np.abs((output_train_x - train_y)/train_y))\n",
    "        losses.append(loss)\n",
    "        accs.append(accuracy)\n",
    "\n",
    "        # backporpagation 연산(weight와 bias 업데이트)\n",
    "        G_loss = 1.0\n",
    "        \n",
    "        g_loss_suqare = np.ones(diff.shape) / np.prod(diff.shape)\n",
    "        g_square_diff = 2*diff\n",
    "        g_diff_outout = 1\n",
    "\n",
    "        G_square = g_loss_suqare * G_loss\n",
    "        G_diff = g_square_diff * G_square\n",
    "        G_output = g_diff_outout * G_diff\n",
    "\n",
    "        g_outout_w = train_x.transpose()\n",
    "\n",
    "        G_w = np.matmul(g_outout_w,G_output)\n",
    "        G_b = np.sum(G_output, axis=0)\n",
    "\n",
    "        weight -= LEARNING_LATE * G_w\n",
    "        bias -= LEARNING_LATE * G_b\n",
    "\n",
    "    if report > 0 and (epoch+1) % report == 0:\n",
    "        test_data = data[shuffle_map[test_begin_idx:]]\n",
    "        test_x = test_data[:, :-output_cnt]\n",
    "        test_y = test_data[:, -output_cnt:]\n",
    "        output_test_x = np.matmul(test_x,weight) + bias\n",
    "        acc= 1 - np.mean(np.abs((output_test_x - test_y)/test_y))\n",
    "        print('Epoch {}: loss={:5.3f}, accuracy={:5.3f}/{:5.3f}'. \\\n",
    "              format(epoch+1,np.mean(losses),np.mean(accs),acc))\n",
    "\n",
    "output_test_x = np.matmul(test_x,weight) + bias\n",
    "final_acc= 1 - np.mean(np.abs((output_test_x - test_y)/test_y))\n",
    "print('\\nFinal Test : final accuracy = {:5.3f}'.format(final_acc))      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
